{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPZVAjvm4NzMyDrHryXazNQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gihuni99/Basic_MLDL/blob/main/Ch02_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "c8G5rwsxqcfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy로 데이터 준비하기"
      ],
      "metadata": {
        "id": "ZohP4gkdqycT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "생선 데이터"
      ],
      "metadata": {
        "id": "Gncc_PpUrGvl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-8oBsgTqWIu"
      },
      "outputs": [],
      "source": [
        "fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,\n",
        "                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,\n",
        "                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,\n",
        "                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]\n",
        "fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,\n",
        "                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,\n",
        "                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,\n",
        "                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에는 파이썬 리스트를 순회하여 길이와 무게를 리스트 안의 리스트로 직접 구성하였다.\n",
        "\n",
        "Numpy를 사용하면 더 간편하게 만들 수 있다."
      ],
      "metadata": {
        "id": "F_D-ovYkrKGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "1vsE7QdLraJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy의 column_stack()함수를 사용\n",
        "\n",
        "column_stack()함수는 전달받은 리스트를 일렬로 나열하여 차례로 연결한다.(연결할 리스트는 tuple로 전달"
      ],
      "metadata": {
        "id": "GxtFQAwbrnKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ex)\n",
        "np.column_stack(([1,2,3],[4,5,6]))#tuple형태로 2개의 list전달"
      ],
      "metadata": {
        "id": "iEymITdrrd8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 예시처럼 column_stack을 활용하여 fish_data를 만들어보자"
      ],
      "metadata": {
        "id": "_9WSF7f81KID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_data=np.column_stack((fish_length,fish_weight))\n",
        "print(fish_data[:5])"
      ],
      "metadata": {
        "id": "iFzHnHZy1PJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 target(ground truth) data를 만들어 보자. 이전에는 [1]*35의 형태로 만들었다.\n",
        "\n",
        "이제는 np.ones()와 np.zeros()함수를 통해 더 쉽게 만들 수 있다.\n",
        "\n",
        "ones(), zeros()함수를 통해 원하는 개수만큼의 배열을 만들 수 있다."
      ],
      "metadata": {
        "id": "t3PX-W0z1pXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ex)\n",
        "print(np.ones(5))\n",
        "print(np.zeros(3))"
      ],
      "metadata": {
        "id": "f_3UEmmh2Tum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 배열은 np.concatenate() 함수를 사용하여 연결해보자.\n",
        "\n",
        "np.concatenate((arr1,arr2),axis=정수)의 형태인데, axis는 dimension에 따라 0,1,2 ... 등으로 설정할 수 있다.\n",
        "\n",
        "내가 연결하려는 np.ones()와 np.zeros는 1차원 배열이기 때문에 axis parameter를 설정하지 않아도 axis=0으로 설정된다.\n",
        "\n",
        "또한 axis=1로 설정하면 오류가 발생한다."
      ],
      "metadata": {
        "id": "lMI3P1wV2gdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_target=np.concatenate((np.ones(35),np.zeros(14)))\n",
        "print(fish_target)"
      ],
      "metadata": {
        "id": "jIt5_3mQ40c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scikit-Learn으로 Train set과 Test set 나누기"
      ],
      "metadata": {
        "id": "dIqHhTc35FM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에는 Train set과 Test set을 나눌 때, numpy의 index array를 직접 shuffle해주었다.(이는 다소 번거롭다)\n",
        "\n",
        "따라서 scikit learn의 **train_test_split()**함수를 사용하여 간편하게 분배하여 보겠다.\n",
        "\n",
        "**train_test_split()은 scikit learn의 model_selection 모듈 아래 있다."
      ],
      "metadata": {
        "id": "v5TnatG-5fR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ECO1T7ix6Eyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fish_data와 fish_target 두개의 array를 전달하였으므로 2개씩 나뉘어 총 4개의 배열을 반환\n",
        "\n",
        "train_test_split()은 자체적인 random sedd를 지정할 수 있는 random_state parameter가 존재한다.\n",
        "\n",
        "기본적으로 25%를 test set으로 분배한다.(파라미터를 바꾸는 방법은 뒤에 언급할 예정)"
      ],
      "metadata": {
        "id": "fgTlsQHY65HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input,test_input,train_target,test_target=train_test_split(fish_data,fish_target,random_state=42)"
      ],
      "metadata": {
        "id": "PkS9oDLN6rVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과를 확인해보자\n",
        "\n",
        "train set: 36개의 sample, test set: 13개의 sample로 나뉜 것을 확인할 수 있다.\n",
        "\n",
        "input data는 2-d array, target data는 1-d array이다.\n",
        "\n",
        "test_target 배열을 확인해보았을 때, data가 섞인 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "AmzNPVfs7hYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input.shape,test_input.shape)\n",
        "print(train_target.shape,test_target.shape)\n",
        "print(test_target)"
      ],
      "metadata": {
        "id": "38-Gu5z17jAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_target을 보면 도미와 빙어가 10:3으로 약 3.3:1의 비율로 섞인 것을 볼 수 있다.\n",
        "\n",
        "하지만 총 데이터는 35:14로, 2.5:1이다. 즉, Sampling bias가 발생한 것이다.\n",
        "\n",
        "이는 train_test_split()함수의 **stratify** parameter를 통해 해결 가능하다. **stratify** parameter에 target data를 전달하면 class의 비율에 맞게 데이터를 분배한다."
      ],
      "metadata": {
        "id": "9dPEdRqc8N8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input,test_input,train_target,test_target=train_test_split(fish_data,fish_target,stratify=fish_target,random_state=42)"
      ],
      "metadata": {
        "id": "pkCn32Qa9lix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13:4, 약 2.25:1의 비율로 fish_target의 비율과 비슷해진 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "D3d16sI193wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_target)"
      ],
      "metadata": {
        "id": "Cqhbovcr90qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 수상한 도미 한 마리"
      ],
      "metadata": {
        "id": "7C9YJJdm-MI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 준비한 데이터로 k-nearest neighbors 모델을 training해보겠다.(앞서 공부했듯이 k-nearest neighbors는 training data를 저장하는 것이 훈련의 전부이다.)\n",
        "\n",
        "결과는 동일하게 정확도 100%이다."
      ],
      "metadata": {
        "id": "Eg8YMMOD-QUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "kn=KNeighborsClassifier()\n",
        "kn.fit(train_input,train_target)\n",
        "kn.score(test_input,test_target)"
      ],
      "metadata": {
        "id": "rQTl9w85-O1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하지만 새로운 도미 데이터를 넣었을 때, 제대로 예측하지 못한다."
      ],
      "metadata": {
        "id": "NdentVEX-4U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(kn.predict([[25,150]]))"
      ],
      "metadata": {
        "id": "7xhqLjgT-4oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 결과를 보면 삼각형(새롭게 입력한 데이터)는 도미의 데이터에 더 가깝다.\n",
        "\n",
        "하지만 결과를 예측하지 못한다."
      ],
      "metadata": {
        "id": "eoOdCOO0_oOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(train_input[:,0],train_input[:,1])\n",
        "plt.scatter(25,150,marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-3ewf-Pw_Mio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "k-nearest neighbors는 주변 sample들 중에서 다수인 클래스를 예측으로 사용한다.\n",
        "\n",
        "KNeighborsClassifier 클래스는 sample에서 가장 가까운 이웃을 찾아주는 제공하는 **kneighbors()** method를 제공\n",
        "\n",
        "**kneighbors()**는 neighbors까지의 distance와 index를 반환한다.\n",
        "\n",
        "KNeighborsClassifier클래스의 이웃 개수인 n_neighbors의 기본값은 5이므로 5개의 이웃이 반환된다.\n",
        "\n"
      ],
      "metadata": {
        "id": "k4hOBCr0AUod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances,indexes=kn.kneighbors([[25,150]]) #[25,150]의 데이터 가장 가까운 sample 5개의 distance와 index가 numpy array형태로 반환된다."
      ],
      "metadata": {
        "id": "KnEoaL9vAOqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(distances)\n",
        "print(indexes)"
      ],
      "metadata": {
        "id": "_yTZSwDYDGmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 결과를 보면 가장 가까운 이웃에 도미가 하나만 포함된 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "ttNfoLmbFOe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train_input[:,0],train_input[:,1])\n",
        "plt.scatter(25,150,marker='^')#scatter()함수에서 marker를 '^'로 지정하면 세모, 'D'로 지정하면 마름모로 scatter plot(산점도)를 그린다.\n",
        "plt.scatter(train_input[indexes,0],train_input[indexes,1],marker='D')#여기에서 numpy array indexing을 사용(indexes에 해당하는 데이터만을 표시하기 위함)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4rKdJsDIENLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input[indexes])"
      ],
      "metadata": {
        "id": "PMB-H6b0FXxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_target[indexes])"
      ],
      "metadata": {
        "id": "QemLrf34FbBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 결과를 보면 distance값이 정확하지 않은 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "0Mof5r6BFwpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(distances)"
      ],
      "metadata": {
        "id": "9lX2_AngFtlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기준을 맞춰라"
      ],
      "metadata": {
        "id": "rHmxC5THF7Y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위처럼 결과가 나온 원인은 weight의 범위는 0-1000인데, length의 범위는 10-40이기 때문이다. 따라서 length의 차이가 커도 distance값은 작은 것\n",
        "\n",
        "따라서 x축의 범위도 xlim()함수를 사용하여 0-1000으로 지정해보면 아래 결과와 같다."
      ],
      "metadata": {
        "id": "ZoRRaGsMJHmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train_input[:,0],train_input[:,1])\n",
        "plt.scatter(25,150,marker='^')\n",
        "plt.scatter(train_input[indexes,0],train_input[indexes,1],marker='D')\n",
        "plt.xlim((0,1000))\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JBQsELpgF_Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 scatter plot을 보면 거의 일직선 형태로 나타나는 것을 볼 수 있다. 이렇게 되면 length는 distance에 거의 영향을 주지 못한다.\n",
        "\n",
        "이는 length와 weight의 **Scale**이 다르다고 표현한다. 즉, Feature의 Scale이 다르다.\n",
        "\n",
        "예시로 weight는 kg단위, length는 cm단위라고 했을 때, 1kg과 1cm 중 어떤 것이 더 크고 작은지는 단위가 다르기 때문에 비교할 수 없다. 따라서 Feature의 기준을 맞추어야 한다. 이를 **Data preprocessing(데이터 전처리)**라고 한다."
      ],
      "metadata": {
        "id": "A6gLIP3OKAP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 많이 사용하는 Data preprocessing은 **Standard Score(표준점수)**이다.\n",
        "\n",
        "**Standard Score**는 각 Feature값이 평균에서 표준편차의 몇배만큼 떨어져 있는지를 나타낸다."
      ],
      "metadata": {
        "id": "za7LPFNQMxAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "np.mean()함수는 평균을 계산, np.std()함수는 표준편차를 계산\n",
        "\n",
        "평균과 표준편차는 각 Feature마다 계산해주어야 한다. 따라서 axis=0으로 설정(axis=0이면 행을 따라 각 열의 통계값을 계산)"
      ],
      "metadata": {
        "id": "mZjpAbt8Npgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_input은 (36,2)의 배열\n",
        "mean=np.mean(train_input,axis=0) #평균\n",
        "std=np.std(train_input,axis=0) #표준편차\n",
        "print(mean,std)"
      ],
      "metadata": {
        "id": "jwQ5qdfAM_Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 결과에서 각 Feature length와 weight의 mean, std값을 알 수 있다.\n",
        "\n",
        "이를 (원본데이터 - 평균값)/표준편차 를 해주면 standard score(표준 점수)를 알 수 있다."
      ],
      "metadata": {
        "id": "VslIovLyOfM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy는 Broadcasting(브로드캐스팅) 기능을 제공한다. broadcasting은 numpy 배열 사이에서 일어나고, 모양이 다른 배열들 간의 연산이 어떤 조건을 만족했을 때 가능해지도록 배열을 자동적으로 변환하는 것이다.\n",
        "\n",
        "(아래의 train_input, mean, std 모두 numpy 배열임을 알 수 있다.)\n",
        "\n",
        "broadcasting을 통해 mean과 std 연산을 모든 행에 적용할 수 있다."
      ],
      "metadata": {
        "id": "luCZxaO3PGi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_scaled=(train_input-mean)/std\n",
        "print(train_scaled)"
      ],
      "metadata": {
        "id": "nntaek5rO16H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Data로 Model Training"
      ],
      "metadata": {
        "id": "FUJkK9OJTQVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 데이터를 standard score로 변환한 train_scaled를 scatter plot으로 그려보자"
      ],
      "metadata": {
        "id": "JiVG2MclTZhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train_scaled[:,0],train_scaled[:,1])\n",
        "plt.scatter(25,150,marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NLlEQpSOUNIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 결과를 보면 새로운 sample [25,150]이 다른 sample들과 멀리 떨어져 있는 것을 볼 수 있다.\n",
        "\n",
        "이는 train set를 standard score로 변환하여 나타냈는데, sample은 변환하지 않았기 대문에 발생한 것이다. 따라서 새로운 sample도 standard score로 변환해주어야 한다."
      ],
      "metadata": {
        "id": "8yr7gqqhU5pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new=([25,150]-mean)/std\n",
        "plt.scatter(train_scaled[:,0],train_scaled[:,1])\n",
        "plt.scatter(new[0],new[1],marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BGExOLh8ViEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 결과를 통해 새로운 sample은 standard score로 변환하면 정상적인 결과가 나오는 것을 알 수 있다.\n",
        "\n",
        "(weight와 length Feature의 범위도 -1.5 ~ 1.5로 바뀌었다)\n",
        "\n",
        "이를 바탕으로 모델을 다시 학습시켜보자"
      ],
      "metadata": {
        "id": "CbiuD7CCVyDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kn.fit(train_scaled,train_target)"
      ],
      "metadata": {
        "id": "-pVh5Td4WFcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 결과를 통해 100%정확도로 test set을 예측한 것을 볼 수 있고, 새로운 데이터에 대한 예측도 도미([1])로 예측한 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "_nUcHoE7Wzmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_scaled=(test_input-mean)/std #test_input에 대한 standard score 산출\n",
        "kn.score(test_scaled,test_target)"
      ],
      "metadata": {
        "id": "lhcwnB9yWOWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kn.predict([new]))"
      ],
      "metadata": {
        "id": "bMx0abbLWg2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 확인했던 새로운 데이터에 대한 주변 distance와 index도 확인해보면 정상적인 결과가 나온다."
      ],
      "metadata": {
        "id": "GlaZOwvIXA18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**standard score**을 통해 Feature의 Scale에 민감하지 않고 안정적인 예측이 가능해졌다."
      ],
      "metadata": {
        "id": "1414c6XeXwG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances,indexes=kn.kneighbors([new])\n",
        "plt.scatter(train_scaled[:,0],train_scaled[:,1])\n",
        "plt.scatter(new[0],new[1],marker='^')\n",
        "plt.scatter(train_scaled[indexes,0],train_scaled[indexes,1],marker='D')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AmLPJgr-XJv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추가적인 공부"
      ],
      "metadata": {
        "id": "wYl2x5IcX-O4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### scikit-learn의 핵심 패키지와 함수\n",
        "\n",
        "**1. train_test_split()**\n",
        "\n",
        "데이터를 train set과 test set으로 나누는 함수로 여러 개의 array를 전달할 수 있다.\n",
        "* test_size parameter: test set의 비율은 test_size매개변수(기본값은 25%)를 통해 변경할 수 있다.\n",
        "* shuffle parameter: train, test set을 나누기 전 무작위로 섞을지 여부를 결정(기본값은 True)\n",
        "* stratify parameter: class의 label이 담긴 배열(target array)을 전달하면 class 비율에 맞게 train, test set을 나눈다."
      ],
      "metadata": {
        "id": "GKqAXrw-ZGJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. kneighbors()**\n",
        "\n",
        "kneighbors() method는 입력한 데이터에 가장 가까운 데이터를 찾아, 그 데이터와의 distance와 index를 반환한다. 기본적으로 이웃의 개수는 KNeighborsClassifier 클래스 객체를 생성할 때 지정한 개수를 사용(기본값은 5), kneighbors에서도 다른 값으로 바꿀 수 있다.\n",
        "\n",
        "* return_distance parameter: False로 지정하면 index값만 반환(기본값은 True)"
      ],
      "metadata": {
        "id": "b7pbzeZlZOjh"
      }
    }
  ]
}