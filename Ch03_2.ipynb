{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNZcg/yTLIrvM5C7EGSbpXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gihuni99/Basic_MLDL/blob/main/Ch03_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "EDQDpAzZkGVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-NN의 한계"
      ],
      "metadata": {
        "id": "h56QVwrnkU7Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5eb82Z9j7Kp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "perch_length = np.array(\n",
        "    [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0,\n",
        "     21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5,\n",
        "     22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5,\n",
        "     27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0,\n",
        "     36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0,\n",
        "     40.0, 42.0, 43.0, 43.0, 43.5, 44.0]\n",
        "     )\n",
        "perch_weight = np.array(\n",
        "    [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,\n",
        "     110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,\n",
        "     130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,\n",
        "     197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,\n",
        "     514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,\n",
        "     820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,\n",
        "     1000.0, 1000.0]\n",
        "     )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data set을 train, test set으로 나눈다."
      ],
      "metadata": {
        "id": "WmB92SEBoc3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input,test_input,train_target,test_target=train_test_split(perch_length,perch_weight,random_state=42)"
      ],
      "metadata": {
        "id": "D-FdKqt6n-qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_input의 shape을 확인해보았을 때, 1차원 배열임을 알 수 있다. scikit learn으로 학습시키기 위해서는 2차원 배열이 되어야 한다."
      ],
      "metadata": {
        "id": "zS7y3U2Gob5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input.shape)"
      ],
      "metadata": {
        "id": "okUlMaWWoXAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reshape()함수를 사용하여 배열의 차원을 바꿔준다."
      ],
      "metadata": {
        "id": "CS5x9_pepCeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input=train_input.reshape(-1,1) #reshape은 numpy에서 제공, (n)*1배열로 변환하므로 42 x 1 array가 된다.\n",
        "test_input=test_input.reshape(-1,1)"
      ],
      "metadata": {
        "id": "E7kJt6TupFr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input.shape)"
      ],
      "metadata": {
        "id": "8tbJha022F0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knr=KNeighborsRegressor(n_neighbors=3) # K=3\n",
        "\n",
        "knr.fit(train_input,train_target)"
      ],
      "metadata": {
        "id": "TZbxiBvQqIlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래에서 학습시킨 모델에 50cm인 농어의 무게를 예측하도록 하였는데, 1033g이 나왔다. 하지만 실제 무게는 더 나간다. 문제가 무엇일까?"
      ],
      "metadata": {
        "id": "qT5mjtvFrHDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(knr.predict([[50]]))"
      ],
      "metadata": {
        "id": "HOFu7NzGrBrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 결과를 보면 가장 가까운 K-neighbors의 무게가 1000에 가깝기 때문에 1033이 예측되는 것은 당연하다."
      ],
      "metadata": {
        "id": "3wTUkYsysTuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "distances,indexes=knr.kneighbors([[50]]) #50cm 농어에 대한 neighbor들의 distance와 index를 구한다.\n",
        "\n",
        "plt.scatter(train_input,train_target) # train set의 scatter plot\n",
        "\n",
        "plt.scatter(train_input[indexes],train_target[indexes],marker='D') #50cm 농어에 대한 K sample을 표시\n",
        "\n",
        "plt.scatter(50,1033,marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mLHRV8flrUJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-neighbors들의 무게 평균을 보면 1033이 나온다. 즉, 45cm 이상인 농어들의 k-neighbors는 항상 40-45사이에 존재하는 sample들이기 때문에 무게를 1033으로 예측할 수 밖에 없다."
      ],
      "metadata": {
        "id": "wGQMwwa4sx-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(train_target[indexes]))"
      ],
      "metadata": {
        "id": "kxHDul61stB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 100cm sample에 대한 무게도 1033으로 예측하는 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "2D1yzlu2tqjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(knr.predict([[100]]))"
      ],
      "metadata": {
        "id": "Ml4t3yhTtm0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "BWkpC36-tx9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**은 feature가 하나일 때, feature를 잘 나타낼 수 있는 직선을 학습하는 알고리즘"
      ],
      "metadata": {
        "id": "_hCFh3uEuNFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scikit-learn은 sklearn.linear_model패키지 아래 **LinearRegression**클래스를 구현\n",
        "\n",
        "LinearRegression 클래스에도 fit(),score(),predict() method 존재"
      ],
      "metadata": {
        "id": "81X609UsucjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr=LinearRegression() #모델\n",
        "\n",
        "lr.fit(train_input,train_target) #모델 학습\n",
        "\n",
        "print(lr.predict([[50]])) #50cm 농어에 대한 예측값 출력"
      ],
      "metadata": {
        "id": "wluhPV-Ut0dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 결과를 통해 올바르게 예측한 것을 알 수 있다."
      ],
      "metadata": {
        "id": "ZL350gbkvONm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression에서 하나의 직선을 그리기 위해서는 기울기와 절편이 필요\n",
        "\n",
        "농어무게=a x 농어길이 + b, 즉 데이터를 가장 잘 표현할 수 있는 a, b값을 찾는 것이다.\n",
        "\n",
        "a, b parameter는 lr객체의 **coef_**와 **intercept_**에 저장되어 있다. coef_는 기울기 값으로 coefficient(계수) 또는 weight(가중치)라고 부른다."
      ],
      "metadata": {
        "id": "vUv6uEPhvSr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.coef_,lr.intercept_)"
      ],
      "metadata": {
        "id": "03ZGu9W-v_4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같은 coef_와 intercept_를 model parameter라고 한다. 즉 training과정은 최적의 model parameter를 찾는 것이다.\n",
        "\n",
        "위 결과를 통해\n",
        "\n",
        "농어의 무게= 39 x 농어의 길이 - 709 의 식이 regression되었다는 것을 알 수 있다."
      ],
      "metadata": {
        "id": "_MNVkuwjwXsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(50*lr.coef_+lr.intercept_)\n",
        "print(15*lr.coef_+lr.intercept_)\n",
        "print(lr.coef_.shape)\n",
        "print(lr.intercept_.shape)"
      ],
      "metadata": {
        "id": "By5ttq7-26CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 Linear Regression된 직선을 그린 결과가 있다."
      ],
      "metadata": {
        "id": "BVPXYjhK50Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train_input,train_target)\n",
        "\n",
        "plt.plot([15,50],[15*lr.coef_+lr.intercept_,50*lr.coef_+lr.intercept_]) #15-50 범위의 1차 방정식\n",
        "\n",
        "plt.scatter(50,1241.8,marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BGG-doKZxVvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과를 보면 train set과 test set의 차이가 다소 있고, train set의 결과도 좋지 않다. 이를 통해 Underfitting되었다는 것을 알 수 있다.\n",
        "\n",
        "또한 위 그래프에서 lenghth가 15이하인 생선의 무게가 음수가 나오는 것을 볼 수 있는데, 이도 옳지 않다."
      ],
      "metadata": {
        "id": "xe7C3dRP6eZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.score(train_input,train_target))\n",
        "print(lr.score(test_input,test_target))"
      ],
      "metadata": {
        "id": "1T1xvFHA56d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polynomial Regression(다항 회귀)"
      ],
      "metadata": {
        "id": "kmepNich67Hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 예시에서 Linear Regression의 직선은 나올 수 없는 예측값(음수)을 포함한다. 따라서 **Polynomial Regression**을 통해 최적의 곡선을 찾는 것이 더 좋아보인다."
      ],
      "metadata": {
        "id": "8YMItZdpCBbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "농어의 무게 = a x $길이^2$ + b x 길이 + c 의 식으로 나타낼 수 있다.\n",
        "\n",
        "위 식을 그리기 위해서는 $길이^2$값을 train set에 추가해야 한다.\n",
        "\n",
        "np.column_stack을 사용해보자"
      ],
      "metadata": {
        "id": "_8uUIzptCV0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_poly=np.column_stack((train_input**2,train_input))\n",
        "test_poly=np.column_stack((test_input**2,test_input))"
      ],
      "metadata": {
        "id": "8DDG7TiQCyOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_poly.shape)\n",
        "print(test_poly.shape)"
      ],
      "metadata": {
        "id": "9iz8Kd7-C_H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 데이터로 모델을 학습시켜보자\n",
        "\n",
        "predict를 할 때에는 feature값이 2개(사실 상 길이 하나이지만 길이의 제곱도 feature라고 한다면)이므로 [50**2, 50]을 넣어준다."
      ],
      "metadata": {
        "id": "XB4YesQwDfxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr=LinearRegression()\n",
        "lr.fit(train_poly,train_target)\n",
        "\n",
        "print(lr.predict([[50**2,50]]))"
      ],
      "metadata": {
        "id": "23e4COsYDh2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression으로 예측한 값보다 더 높은 값은 예측했다.\n",
        "\n",
        "아래에서 model parameter를 확인해보면, weight값(a,b)는 각각 1.01433211, -21.55792498이 나왔고, bias(c)는 116.0502107827827이 나왔다.\n",
        "\n",
        "대략적인 식으로 나타내면 무게 = 1.01*$길이^2$ - 21.6 * 길이 + 116 이다."
      ],
      "metadata": {
        "id": "HklhXP67D8Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.coef_,lr.intercept_)"
      ],
      "metadata": {
        "id": "TZpK8NyUEBcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+) Polynomial Regression도 Linear Regression이다. 위에서 $길이^2$값을 '큰 길이'라고 정의 한다면, 무게=1.01*'큰 길이'-21.6*길이+116이라고 식을 세울 수 있다. 즉 무게는 '큰길이'와 길이의 선형관계로 나타낼 수 있는 것이다."
      ],
      "metadata": {
        "id": "QIEzlBpMFIi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "point=np.arange(15,50)\n",
        "\n",
        "plt.scatter(train_input,train_target)\n",
        "\n",
        "plt.plot(point,1.01*point**2-21.6*point+116.05)\n",
        "\n",
        "plt.scatter(50,1574,marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HpNvir1tFsHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과를 확인해보면 육안상으로는 데이터를 더 잘 표현하는 그래프가 그려졌다.\n",
        "\n",
        "score도 train, test set 모두의 정확도가 올라간 것을 볼 수 있다. 다만 test set의 score가 train보다 높은 것을 보면 아직 Underfitting이 완벽하게 해결되지 않았다는 것을 알 수 있다."
      ],
      "metadata": {
        "id": "YsyPqvvIGV17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.score(train_poly,train_target))\n",
        "print(lr.score(test_poly,test_target))"
      ],
      "metadata": {
        "id": "lCFQRsDuGI9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정리** K-NN Regression은 train set 바깥의 범위에 존재하는 sample에 대한 예측을 할 수 없다. 이를 Linear, Polynomial Regression으로 해결해보았다."
      ],
      "metadata": {
        "id": "UuoCGNTXGro4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추가공부"
      ],
      "metadata": {
        "id": "pHo7Y2ePG7s4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scikit-Learn**\n",
        "* **LinearRegression**: scikit-learn의 linear regression 클래스이다. 'fit_intercept' parameter를 False로 지정하면 절평(bias)를 학습하지 않는다. 학습된 모델의 coef_ 는 feature에 대한 계수를 가지고 있는 배열이다. 따라서 coef_ 배열의 크기는 feature의 개수와 같다. intercept_에는 bias가 포함되어 있다."
      ],
      "metadata": {
        "id": "1K9vJI0RPFEH"
      }
    }
  ]
}